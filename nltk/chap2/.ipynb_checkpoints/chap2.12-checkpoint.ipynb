{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6d0ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /home/nicolas/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nicolas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('tagsets')\n",
    "from nltk.data import load\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e91a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS']\n"
     ]
    }
   ],
   "source": [
    "def get_tagsets():\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "    return list(tagdict.keys())\n",
    "\n",
    "tag_list = get_tagsets()\n",
    "\n",
    "print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f12d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>VBN</th>\n",
       "      <th>''</th>\n",
       "      <th>WP</th>\n",
       "      <th>UH</th>\n",
       "      <th>VBG</th>\n",
       "      <th>JJ</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>--</th>\n",
       "      <th>...</th>\n",
       "      <th>MD</th>\n",
       "      <th>VB</th>\n",
       "      <th>WRB</th>\n",
       "      <th>NNP</th>\n",
       "      <th>EX</th>\n",
       "      <th>NNS</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   MD   VB  WRB  NNP  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    EX  NNS  SYM   CC   CD  POS  \n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This method will count the occurence of pos\n",
    "tags in each sentence.\n",
    "\"\"\"\n",
    "def get_pos_occurence_freq(data, tag_list):\n",
    "    # Get list of sentences in text_list\n",
    "    text_list = data.text\n",
    "    \n",
    "    # Create empty dataframe\n",
    "    feature_df = pd.DataFrame(columns=tag_list)\n",
    "    for text_line in text_list:\n",
    "        \n",
    "        # Get pos tags of each world.\n",
    "        pos_tags = [j for i, j in pos_tag(word_tokenize(text_line))]\n",
    "        \n",
    "        \"\"\"\n",
    "        create a dict of pos tags and their frequency\n",
    "        in given sentence\n",
    "        \"\"\"\n",
    "        row = dict(Counter(pos_tags))\n",
    "        feature_df = feature_df.append(row, ignore_index=True)\n",
    "    feature_df.fillna(0, inplace=True)\n",
    "    return feature_df\n",
    "tag_list = get_tagsets()\n",
    "\n",
    "data = pd.read_csv('data/data.csv', header=0)\n",
    "feature_df = get_pos_occurence_freq(data, tag_list)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fe765f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: num_of_unique_punctuations, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_punctuation_count(feature_df, data):\n",
    "    feature_df['num_of_unique_punctuations'] = data['text'].apply(lambda x: len(set(x).\\\n",
    "                                                                                intersection(set(punctuation))))\n",
    "    return feature_df\n",
    "\n",
    "feature_df = add_punctuation_count(feature_df, data)\n",
    "feature_df['num_of_unique_punctuations'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd388861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: number_of_capital_words, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_capitalized_word_count(feature_df, data):\n",
    "    \"\"\"\n",
    "    The bellow code line will tokenize text in every row and\n",
    "    create a set of only capital words, ten find the length of\n",
    "    this set and add it to the column 'number_of_capital_words'\n",
    "    \"\"\"\n",
    "    feature_df['number_of_capital_words'] = data['text'].apply(lambda x: len([word for word in word_tokenize(str(x))\\\n",
    "                                                                              if word[0].isupper()]))\n",
    "    return feature_df\n",
    "\n",
    "feature_df = get_capitalized_word_count(feature_df, data)\n",
    "\n",
    "feature_df['number_of_capital_words'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac61d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_word_count(feature_df, data):\n",
    "    \"\"\"\n",
    "    The bellow code will tokenize text in every row and\n",
    "    create a set of only small words, then find the length of\n",
    "    this set of only small words, then find the length of\n",
    "    this set and add it to the column, 'number_of_small_words'\n",
    "    of dataframe\n",
    "    \"\"\"\n",
    "    feature_df['number_of_small_words'] = data['text'].apply(lambda x: len([word for word in\\\n",
    "                                                                        word_tokenize(str(x)) if word[0].islower()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
