{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('She lived in NewHampshire.')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'she', 0),\n",
       " ('lived', 'live', 1),\n",
       " ('in', 'in', 2),\n",
       " ('NewHampshire', 'NewHampshire', 3),\n",
       " ('.', '.', 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.lemma_, token.i) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('She', 'PRON', 'PRP', 'nsubj')\n",
      "('lived', 'VERB', 'VBD', 'ROOT')\n",
      "('in', 'ADP', 'IN', 'prep')\n",
      "('NewHampshire', 'PROPN', 'NNP', 'pobj')\n",
      "('.', 'PUNCT', '.', 'punct')\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print((token.text, token.pos_, token.tag_, token.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'she', 0, lived),\n",
       " ('lived', 'live', 1, lived),\n",
       " ('in', 'in', 2, lived),\n",
       " ('New', 'New', 3, Hampshire),\n",
       " ('Hampshire', 'Hampshire', 4, in),\n",
       " ('.', '.', 5, lived)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with doc.retokenize() as retokenizer:\n",
    "    heads = [(doc[3], 1), doc[2]]\n",
    "    attrs = {'TAG': ['NNP', 'NNP'], \n",
    "             'DEP': ['compound', 'pobj']}\n",
    "    retokenizer.split(doc[3], ['New', 'Hampshire'], heads=heads, attrs=attrs)\n",
    "\n",
    "[(token.text, token.lemma_, token.i, token.head) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('She', 'PRON', 'PRP', 'nsubj')\n",
      "('lived', 'VERB', 'VBD', 'ROOT')\n",
      "('in', 'ADP', 'IN', 'prep')\n",
      "('New', 'PROPN', 'NNP', 'compound')\n",
      "('Hampshire', 'PUNCT', 'NNP', 'pobj')\n",
      "('.', 'PUNCT', '.', 'punct')\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print((token.text, token.pos_, token.tag_, token.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "788ff9e221da96786f0787fa034c6a6d4ee2301f6a202844060c0567f22b56e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
